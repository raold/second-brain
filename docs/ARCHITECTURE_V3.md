# Second Brain v3.0.0 - Architecture Documentation

## Executive Summary

Second Brain v3.0.0 implements a **Docker-first development architecture** with clean separation of concerns, service-oriented design, and bulletproof cross-platform development experience.

## ðŸŽ¯ Development-First Architecture

### Core Philosophy: Zero Friction Development

Second Brain v3.0.0 prioritizes **developer experience** above all else:

- **ðŸ³ Docker-First**: No host dependencies, identical environments everywhere
- **ðŸ”’ Bulletproof Fallback**: Automated .venv creation when Docker unavailable  
- **âš¡ One-Command Setup**: `make setup` works on any machine instantly
- **ðŸŒ Cross-Platform**: Windows, macOS, Linux with zero configuration

## Core Architecture Principles

### 1. Service-Oriented Architecture  
- **Clean Separation**: Business logic in `app/services/`
- **Route Delegation**: Thin controllers delegate to service layer
- **Repository Pattern**: Data access abstraction
- **Dependency Injection**: Service factory pattern

### 2. Docker-First Infrastructure
- **Container Parity**: Development == Production environments
- **Multi-Stage Builds**: Optimized development and production images  
- **Service Composition**: App, PostgreSQL, Redis in docker-compose
- **Volume Management**: Persistent data, excluded .venv

### 3. Cross-Platform Development
- **Universal Scripts**: `scripts/dev` works on Windows/Mac/Linux
- **Smart Detection**: Automatic Docker vs .venv selection
- **Platform Scripts**: Auto-generated activation for each OS
- **Makefile Intelligence**: Commands adapt to environment

### 4. Bulletproof Environment Management
- **Automated .venv**: `scripts/setup-bulletproof-venv.py` 
- **Health Validation**: Automatic dependency and import checks
- **Error Recovery**: Self-healing environment setup
- **Activation Scripts**: `activate-venv.bat` and `activate-venv.sh`

## System Architecture

```mermaid
graph TB
    subgraph "Client Layer"
        WEB[Web Client]
        API_CLIENT[API Client]
        CLI[CLI Tools]
    end
    
    subgraph "API Layer"
        NGINX[Nginx/Load Balancer]
        API[FastAPI Application]
        MW[Middleware]
    end
    
    subgraph "Application Layer"
        UC1[Memory Use Cases]
        UC2[Session Use Cases]
        UC3[Search Use Cases]
        UC4[Tag Use Cases]
        DTO[DTOs]
    end
    
    subgraph "Domain Layer"
        MEM[Memory Aggregate]
        SES[Session Aggregate]
        TAG[Tag Value Object]
        USER[User Entity]
        EVT[Domain Events]
    end
    
    subgraph "Infrastructure Layer"
        subgraph "Persistence"
            PG[(PostgreSQL + pgvector)]
            REDIS[(Redis Cache)]
        end
        
        subgraph "Messaging"
            RABBIT[RabbitMQ]
            WORKER[Event Workers]
        end
        
        subgraph "Storage"
            MINIO[(MinIO/S3)]
        end
        
        subgraph "External"
            OPENAI[OpenAI API]
        end
    end
    
    subgraph "Observability"
        OTEL[OpenTelemetry]
        PROM[Prometheus]
        LOGS[Structured Logging]
    end
    
    WEB --> NGINX
    API_CLIENT --> NGINX
    CLI --> NGINX
    
    NGINX --> API
    API --> MW
    MW --> UC1
    MW --> UC2
    MW --> UC3
    MW --> UC4
    
    UC1 --> MEM
    UC2 --> SES
    UC3 --> MEM
    UC4 --> TAG
    
    MEM --> EVT
    SES --> EVT
    
    UC1 --> PG
    UC1 --> REDIS
    UC1 --> RABBIT
    UC1 --> MINIO
    UC1 --> OPENAI
    
    RABBIT --> WORKER
    WORKER --> PG
    
    API --> OTEL
    OTEL --> PROM
    API --> LOGS
```

## Directory Structure

```
second-brain/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ domain/                 # Core business logic
â”‚   â”‚   â”œâ”€â”€ models/            # Entities, aggregates, value objects
â”‚   â”‚   â”‚   â”œâ”€â”€ memory.py      # Memory aggregate root
â”‚   â”‚   â”‚   â”œâ”€â”€ session.py     # Session aggregate
â”‚   â”‚   â”‚   â”œâ”€â”€ tag.py         # Tag value object
â”‚   â”‚   â”‚   â””â”€â”€ user.py        # User entity
â”‚   â”‚   â”œâ”€â”€ events/            # Domain events
â”‚   â”‚   â”‚   â”œâ”€â”€ base.py        # Event base classes
â”‚   â”‚   â”‚   â”œâ”€â”€ memory_events.py
â”‚   â”‚   â”‚   â”œâ”€â”€ session_events.py
â”‚   â”‚   â”‚   â””â”€â”€ user_events.py
â”‚   â”‚   â””â”€â”€ repositories/      # Repository interfaces
â”‚   â”‚       â”œâ”€â”€ memory_repository.py
â”‚   â”‚       â”œâ”€â”€ session_repository.py
â”‚   â”‚       â””â”€â”€ event_store.py
â”‚   â”‚
â”‚   â”œâ”€â”€ application/           # Application business logic
â”‚   â”‚   â”œâ”€â”€ use_cases/        # Business operations
â”‚   â”‚   â”‚   â”œâ”€â”€ memory_use_cases.py
â”‚   â”‚   â”‚   â”œâ”€â”€ session_use_cases.py
â”‚   â”‚   â”‚   â””â”€â”€ tag_use_cases.py
â”‚   â”‚   â”œâ”€â”€ dto/              # Data transfer objects
â”‚   â”‚   â”‚   â”œâ”€â”€ memory_dto.py
â”‚   â”‚   â”‚   â””â”€â”€ session_dto.py
â”‚   â”‚   â”œâ”€â”€ services/         # Application services
â”‚   â”‚   â”‚   â””â”€â”€ attachment_service.py
â”‚   â”‚   â””â”€â”€ exceptions.py     # Application exceptions
â”‚   â”‚
â”‚   â”œâ”€â”€ infrastructure/        # External concerns
â”‚   â”‚   â”œâ”€â”€ database/         # PostgreSQL implementation
â”‚   â”‚   â”‚   â”œâ”€â”€ models.py     # SQLAlchemy models
â”‚   â”‚   â”‚   â”œâ”€â”€ connection.py # Database connection
â”‚   â”‚   â”‚   â””â”€â”€ repositories/ # Concrete repositories
â”‚   â”‚   â”œâ”€â”€ caching/          # Redis implementation
â”‚   â”‚   â”‚   â”œâ”€â”€ cache.py      # Cache client
â”‚   â”‚   â”‚   â”œâ”€â”€ strategies.py # Caching strategies
â”‚   â”‚   â”‚   â””â”€â”€ decorators.py # Cache decorators
â”‚   â”‚   â”œâ”€â”€ messaging/        # RabbitMQ implementation
â”‚   â”‚   â”‚   â”œâ”€â”€ broker.py     # Message broker
â”‚   â”‚   â”‚   â”œâ”€â”€ publisher.py  # Event publisher
â”‚   â”‚   â”‚   â””â”€â”€ handlers.py   # Event handlers
â”‚   â”‚   â”œâ”€â”€ storage/          # MinIO/S3 implementation
â”‚   â”‚   â”‚   â”œâ”€â”€ client.py     # Storage client
â”‚   â”‚   â”‚   â””â”€â”€ models.py     # Storage models
â”‚   â”‚   â”œâ”€â”€ embeddings/       # OpenAI integration
â”‚   â”‚   â”‚   â””â”€â”€ client.py     # Embedding generator
â”‚   â”‚   â””â”€â”€ observability/    # Monitoring
â”‚   â”‚       â”œâ”€â”€ tracing.py    # OpenTelemetry
â”‚   â”‚       â”œâ”€â”€ metrics.py    # Prometheus
â”‚   â”‚       â””â”€â”€ logging.py    # Structured logging
â”‚   â”‚
â”‚   â””â”€â”€ api/                   # API layer
â”‚       â”œâ”€â”€ app.py            # FastAPI application
â”‚       â”œâ”€â”€ dependencies.py   # Dependency injection
â”‚       â”œâ”€â”€ middleware.py     # Cross-cutting concerns
â”‚       â”œâ”€â”€ exceptions.py     # API exceptions
â”‚       â””â”€â”€ routes/           # API endpoints
â”‚           â”œâ”€â”€ memories.py
â”‚           â”œâ”€â”€ sessions.py
â”‚           â”œâ”€â”€ search.py
â”‚           â””â”€â”€ health.py
â”‚
â”œâ”€â”€ tests/                     # Test suites
â”‚   â”œâ”€â”€ unit/                 # Unit tests
â”‚   â”œâ”€â”€ integration/          # Integration tests
â”‚   â””â”€â”€ e2e/                  # End-to-end tests
â”‚
â”œâ”€â”€ migrations/               # Database migrations
â”œâ”€â”€ docker/                   # Docker configurations
â”œâ”€â”€ k8s/                      # Kubernetes manifests
â””â”€â”€ docs/                     # Documentation
```

## Data Flow

### 1. Memory Creation Flow
```
Client Request â†’ API Route â†’ Validation â†’ Use Case â†’ Domain Model 
â†’ Domain Event â†’ Repository â†’ Database â†’ Event Publisher â†’ Message Queue
â†’ Event Handler â†’ Cache Update â†’ Response
```

### 2. Search Flow
```
Search Request â†’ API Route â†’ Use Case â†’ Cache Check â†’ 
(Cache Miss) â†’ Repository â†’ PostgreSQL Vector Search â†’ 
Cache Update â†’ Response
```

### 3. Event Processing Flow
```
Domain Event â†’ Event Publisher â†’ RabbitMQ â†’ Event Worker â†’
Event Handler â†’ Side Effects (Cache, Notifications, etc.)
```

## Technology Stack

### Core
- **Language**: Python 3.11+
- **Framework**: FastAPI (async-first)
- **ORM**: SQLAlchemy 2.0 (async)

### Data Layer
- **Primary DB**: PostgreSQL 16 with pgvector
- **Cache**: Redis 7+
- **Message Queue**: RabbitMQ 3.12+
- **Object Storage**: MinIO (S3-compatible)

### Observability
- **Tracing**: OpenTelemetry
- **Metrics**: Prometheus
- **Logging**: Structured JSON logs

### Development
- **Testing**: pytest, pytest-asyncio
- **Linting**: Black, Ruff, mypy
- **Pre-commit**: Git hooks
- **CI/CD**: GitHub Actions

## Key Design Patterns

### 1. Repository Pattern
```python
# Domain layer (interface)
class MemoryRepository(Protocol):
    async def save(self, memory: Memory) -> Memory:
        ...
    async def find_by_id(self, id: UUID) -> Optional[Memory]:
        ...

# Infrastructure layer (implementation)
class SQLMemoryRepository:
    async def save(self, memory: Memory) -> Memory:
        # PostgreSQL implementation
        ...
```

### 2. Use Case Pattern
```python
class CreateMemoryUseCase:
    def __init__(self, 
                 memory_repo: MemoryRepository,
                 event_publisher: EventPublisher):
        self._memory_repo = memory_repo
        self._publisher = event_publisher
    
    async def execute(self, request: CreateMemoryRequest) -> Memory:
        # Business logic here
        memory = Memory.create(...)
        await self._memory_repo.save(memory)
        await self._publisher.publish(memory.events)
        return memory
```

### 3. Event Sourcing
```python
@dataclass
class MemoryCreatedEvent(DomainEvent):
    memory_id: UUID
    content: str
    user_id: UUID
    created_at: datetime
    
class Memory(AggregateRoot):
    def __init__(self):
        self._events: List[DomainEvent] = []
    
    @classmethod
    def create(cls, content: str, user_id: UUID) -> 'Memory':
        memory = cls()
        event = MemoryCreatedEvent(...)
        memory._apply(event)
        memory._record(event)
        return memory
```

### 4. Caching Strategy
```python
@cache_aside(ttl=300)
async def get_memory(memory_id: UUID) -> Memory:
    return await memory_repository.find_by_id(memory_id)

@cache_invalidate(pattern="memory:*")
async def update_memory(memory: Memory) -> Memory:
    return await memory_repository.save(memory)
```

## Deployment Architecture

### Development
```bash
# Docker Compose with all services
docker-compose -f docker-compose.dev.yml up
```

### Production (Single Instance)
```bash
# Docker Compose production
docker-compose -f docker-compose.prod.yml up -d
```

### Production (Kubernetes)
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: secondbrain-api
spec:
  replicas: 3
  selector:
    matchLabels:
      app: secondbrain-api
  template:
    spec:
      containers:
      - name: api
        image: secondbrain:v3.0.0
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
```

## Performance Considerations

### 1. Caching Strategy
- **Read-through**: Lazy loading with cache
- **Write-through**: Update cache on writes
- **Cache-aside**: Manual cache management
- **TTL-based**: Automatic expiration

### 2. Database Optimization
- **Connection pooling**: Async connection pool
- **Query optimization**: Indexed queries
- **Vector search**: Optimized pgvector indexes
- **Batch operations**: Bulk inserts/updates

### 3. Async Processing
- **Non-blocking I/O**: FastAPI async endpoints
- **Background tasks**: RabbitMQ workers
- **Concurrent requests**: asyncio concurrency
- **Rate limiting**: API throttling

## Security Architecture

### 1. Authentication & Authorization
- **JWT tokens**: Stateless authentication
- **API keys**: Service-to-service auth
- **RBAC**: Role-based access control
- **Token refresh**: Secure token rotation

### 2. Data Security
- **Encryption at rest**: Database encryption
- **Encryption in transit**: TLS/SSL
- **Secrets management**: Environment variables
- **Input validation**: Pydantic models

### 3. API Security
- **Rate limiting**: Prevent abuse
- **CORS**: Controlled origins
- **Input sanitization**: SQL injection prevention
- **Error handling**: No sensitive data leakage

## Monitoring & Observability

### 1. Metrics (Prometheus)
```python
# Request metrics
request_duration = Histogram(
    'http_request_duration_seconds',
    'HTTP request latency',
    ['method', 'endpoint', 'status']
)

# Business metrics
memories_created = Counter(
    'memories_created_total',
    'Total memories created'
)
```

### 2. Tracing (OpenTelemetry)
```python
@trace
async def create_memory(request: CreateMemoryRequest):
    with tracer.start_as_current_span("create_memory"):
        # Traced operation
        ...
```

### 3. Logging
```python
logger.info(
    "Memory created",
    extra={
        "memory_id": str(memory.id),
        "user_id": str(user_id),
        "trace_id": get_trace_id()
    }
)
```

## Migration Strategy

### From v2.x to v3.0.0
1. **Data Migration**: Scripts to migrate existing data
2. **API Compatibility**: Temporary compatibility layer
3. **Gradual Migration**: Feature flags for new functionality
4. **Rollback Plan**: Database backups and version control

## Future Enhancements

### Short Term (3-6 months)
- GraphQL API support
- WebSocket real-time updates
- Advanced search capabilities
- Multi-language support

### Long Term (6-12 months)
- Microservices architecture
- Event streaming (Kafka)
- Machine learning pipeline
- Federation protocol

## Getting Started

See [README.md](../README.md) for quick start instructions.

## Contributing

See [CONTRIBUTING.md](../CONTRIBUTING.md) for development guidelines.