services:
<<<<<<< HEAD
  llm-output-processor:
    build: .
    container_name: llm_output_processor_staging
    image: ${DOCKER_REGISTRY:-localhost}/llm-output-processor:staging-latest
=======
  second-brain:
    build: .
    container_name: second_brain_staging
    image: ${DOCKER_REGISTRY:-localhost}/second-brain:staging-latest
>>>>>>> a7482b9e847b5f65dc4124534881b2b3c3814b01
    ports:
      - "8001:8000"  # Different port for staging
    depends_on:
      - qdrant-staging
    networks:
      - app-net-staging
    restart: unless-stopped
    environment:
      APP_ENV: staging
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      API_TOKENS: ${STAGING_API_TOKENS}
      OPENAI_EMBEDDING_MODEL: text-embedding-3-small
      LOG_PATH: logs/processor-staging.log
      LOG_LEVEL: INFO
      QDRANT_HOST: qdrant-staging
      QDRANT_PORT: 6333
      QDRANT_COLLECTION_NAME: memories-staging
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  qdrant-staging:
    image: qdrant/qdrant:latest
    container_name: qdrant_staging
    ports:
      - "6334:6333"  # Different port for staging
    volumes:
      - ./qdrant_data_staging:/qdrant/storage
    networks:
      - app-net-staging
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6333"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

networks:
  app-net-staging:
    driver: bridge 