# Second Brain v3.0.0 - Enhanced Pytest Configuration for Tiered Testing

[tool:pytest]
# Test discovery
testpaths = 
    tests/unit
    tests/integration  
    tests/validation
    tests/performance
    tests/comprehensive

python_files = test_*.py *_test.py
python_classes = Test*
python_functions = test_*

# Minimum pytest version
minversion = 7.4

# Add options (optimized for CI/CD pipeline)
addopts = 
    --strict-markers
    --strict-config
    --verbose
    --tb=short
    --color=yes
    --durations=10
    --cov=app
    --cov-report=html:htmlcov
    --cov-report=term-missing:skip-covered
    --cov-report=xml
    --cov-fail-under=70
    --maxfail=10
    --timeout=60

# Python path for imports
pythonpath = . src app

# Asyncio configuration
asyncio_mode = auto

# Logging configuration (reduced for CI performance)
log_cli = false
log_cli_level = WARNING
log_cli_format = %(asctime)s [%(levelname)8s] %(name)s: %(message)s
log_cli_date_format = %Y-%m-%d %H:%M:%S

# Enhanced test markers for tiered strategy
markers =
    # Execution time categories
    fast: Fast tests (<1s per test)
    medium: Medium tests (1-10s per test)
    slow: Slow tests (>10s per test)
    
    # Test type categories
    unit: Unit tests that don't require external dependencies
    integration: Integration tests that require external services
    e2e: End-to-end tests
    performance: Performance and load tests
    
    # CI/CD stage markers
    smoke: Smoke tests for critical path validation
    fast_feedback: Fast feedback tests for core functionality
    comprehensive: Comprehensive validation tests
    
    # Dependency markers
    requires_db: Tests that require database connection
    requires_redis: Tests that require Redis connection
    requires_external: Tests that require external services
    requires_real_db: Tests that require real database (not mocks)
    
    # Reliability markers
    flaky: Tests that may be unreliable (auto-retry enabled)
    quarantine: Tests that are quarantined (run but don't affect pipeline)
    non_blocking: Tests that generate warnings but don't block deployment
    critical: Tests that must pass for deployment
    
    # Feature markers
    api: API endpoint tests
    synthesis: Synthesis feature tests
    security: Security validation tests
    migration: Database migration tests
    
    # Environment markers
    ci: Tests that run in CI pipeline
    local: Tests that only run locally
    docker: Tests that require Docker
    
    # Performance markers
    benchmark: Performance benchmark tests
    load: Load testing tests
    memory: Memory usage tests
    
# Filter warnings (enhanced for cleaner CI output)
filterwarnings =
    ignore::DeprecationWarning
    ignore::PendingDeprecationWarning
    ignore::UserWarning:pydantic
    ignore::pytest.PytestUnraisableExceptionWarning
    ignore::UserWarning:pytest_asyncio
    ignore::ResourceWarning
    ignore::FutureWarning:httpx
    
# Environment variables for testing
env =
    TESTING = true
    PYTHONIOENCODING = utf-8
    ENVIRONMENT = test
    LOG_LEVEL = WARNING
    DEBUG = false
    
# Test execution configuration
# Timeout configuration (per test)
timeout = 60
timeout_method = thread

# Retry configuration for flaky tests  
flaky_reruns = 2
flaky_reruns_delay = 1

# Parallel execution settings
# (Use -n auto for auto-detection of CPU cores)
# pytest-xdist settings applied via command line

# Coverage configuration
cov_context = test
cov_branch = true

# Test data and fixtures
cache_dir = .pytest_cache
tmp_path_retention_count = 3
tmp_path_retention_policy = failed

# Custom collection order (fastest first)
collection_order = 
    --collect-only
    -m "fast"
    -m "not slow and not performance"
    -m "slow or performance"